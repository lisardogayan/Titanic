---
title: "Práctica 2."
author: 
- "Lisardo Gayán"
- "José Luis Melo"
date: '`r format(Sys.Date(),"%e %B, %Y")`'
output:
  pdf_document:
    highlight: default
    number_sections: no
    toc: yes
    toc_depth: 3
  html_document:
    highlight: default
    number_sections: no
    theme: cosmo
    toc: yes
    toc_depth: 3
    toc_float: yes
bibliography: biblio.bib
nocite: '@*'    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r  Librerias , include=FALSE, eval = TRUE}
library(knitr)
library(kableExtra)
library(ggplot2)
library(dplyr)
library(stringr)
library(caTools)
library(scales)
library(car)
library(rpart)
library(ggpubr)
```


# 1 - Descripción del dataset.  
**¿Por qué es importante y qué pregunta/problema pretende responder?**  

El dataset de Titanic: Machine Learning from Disaster se registran los datos de los pasajeros del famoso trasatlántico y se utiliza para predecir los supervivientes. Los datos estan divididos en dos dataset, uno de test y otro entrenamiento, para la creación de modelos de predicción.

# 2 - Integración y selección de los datos de interés a analizar

Se importan los datos. Primero el dataset train.


```{r Importacion datos train}
datostrain <- read.csv("./data/train.csv", stringsAsFactors = FALSE, na.strings = c("NA", ""))
str(datostrain)
```

Se observa como consta de 891 muestras y 12 variables, entre ellas Survived.

Posteriormente el dataset test.

```{r Importacion datos test}
datostest <- read.csv ("./data/test.csv", stringsAsFactors = FALSE, na.strings = c("NA", ""))
str(datostest)
```

Se compone de 418 observaciones y 11 variables. La variable Survived no aparece debido a que es la que se debe predecir.
   
A continuacion, a la hora de fusionar los datos caben dos posibilidades, asignar "NA" a la variable datostest$Survived o no considerar los datos de survived en train. Se importan, fusionan los datos y se revisa la estructura inicial de los datos.  

```{r Unión datos}
datostest$Survived <- NA
datos <- rbind(datostrain, datostest)
str(datos)
```

A continuación comprobamos los datos que faltan.

```{r Check valores faltantes}
# Buscamos primero qué variables tienen valores perdidos
missing_numbers <- sapply(datos, function(x) {sum(is.na(x))})
kable(data.frame(Variables = names(missing_numbers), Datos_faltantes= as.vector(missing_numbers))) %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

Podemos observar, que en Survived, salen los 418, que tenemos que predecir, por lo que todos los valores de train están informados.

A continuación se detallan las variables y su tipo inicial, este último, se modificara para su mejor análisis. 


```{r Prescindimos de survived}
# datostrain1 <- datostrain[,-2]
# data <- rbind(datostrain1, datostest) # Fusion datasets
data <- datos[,-2]
str(data)
```

```{r Tipos de Variables Original}
tipos <- sapply(data, class)
kable(data.frame(Variables = names(tipos), Tipo_Variable= as.vector(tipos))) %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

Las variables, que no tienen datos faltantes, class y sex, se convertiran a factor. La variable cabin tiene muchos datos faltantes, así que en un primer momento no se utilizará. 

```{r Conversion Variables}
#data$Age <- as.integer(data$Age)
data$Pclass <- as.factor(data$Pclass)
data$Sex <- as.factor(data$Sex)
#data$Embarked <- as.factor(data$Embarked)
#data$Cabin <- as.factor(data$Cabin)
tipos_new <- sapply(data, class)
kable(data.frame(Variables = names(tipos_new), Tipo_Variable= as.vector(tipos_new))) %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

Una vez modificadas los tipos de valores se resume que:

```{r Resumen Variables}
summary(data)
```

PassengerId: Variable de tipo entero que contiene el id del pasajero, no existen valores nulos o perdidos.  
Pclass: Variable de tipo factor con la categoria asignada al pasajero, no existen valores nulos o perdidos.  
Name: Variable de tipo texto con el nombre del pasajero, no existen valores nulos o perdidos.  
Sex: Variable de tipo factor con el genero del pasajero (másculino, femenino), no existen valores nulos o perdidos.  
Age: Variable de tipo numérico que especifica la edad del pasajero, **existen 263 valores nulos.**  
SibSp: Variable de tipo entero que especifica el numero de hermanos/esposa abordo, no existen valores nulos o perdidos.  
Parch: Variable de tipo entero que especifica el numero de padres/hijos abordo, no existen valores nulos o perdidos.  
Ticket: Variable de tipo texto que indica el numero de ticket, no existen valores nulos o perdidos.   
Fare: Variable de tipo numero que especifica la tarifa pagada, **existe 1 valor nulo.**   
Cabin: Variable de tipo factor donde se especifica la cabina asignada, **existen 1014 valores perdidos.**   
Embarked: Variable de tipo factor que indica el puerto de embarque, **existen 2 valores perdidos.**    
  
# 3 - Limpieza de datos

**3.1. ¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos?**  

Volvemos a mostrar los datos que contienen ceros o elementos vacíos.


```{r Check valores faltantes bis}
# Busco primero qué variables tienen valores perdidos
missing_numbers <- sapply(datos, function(x) {sum(is.na(x))})
kable(data.frame(Variables = names(missing_numbers), 
                 Datos_faltantes= as.vector(missing_numbers))) %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```
  

De las variables existentes a continuación se espedifican aquellas que contienen valores perdido o nulos.  

- Age: *existen 263 valores nulos.*  

Para imputar valores de **edad**, se aplicara el algoritmo rpart, que es un árbol de regresión.  

Comprobamos la variable Age

```{r Resumen de Age}
summary(data$Age)
```

Se comprueba como hay 263 valores nulos. 

```{r Asignación de Age}
# Referencia: 
# https://www.rdocumentation.org/packages/rpart/versions/4.1-15/topics/rpart
age_model <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked,
                       data = data[!is.na(data$Age),], method = "anova")
data$Age[is.na(data$Age)] <- predict(age_model, data[is.na(data$Age),])
summary(data$Age)
```

También se podrían imputar por otros métodos, como la media, mediana o mice en lugar del usado rpart.

- Fare: *existe 1 valor nulo.*     
Para imputar valores **Fare**  
Dado que unicamente hay un valor perdido, es posible imputarlo por la media o la mediana en base al puerto de embarque "S" y la clase "3"

```{r Confirmación nulos Fare}
data[is.na(data$Fare),]
M_fare<- subset(data,data$Pclass == '3' & data$Embarked == 'S')
mean(M_fare$Fare, na.rm = T)
median(M_fare$Fare, na.rm = T)
``` 

Realizamos una gráfica de la distribución de valores de Fare.

```{r Plot nulos Fare}
ggplot(M_fare,  aes(x = Fare)) +
  geom_density(fill = 'grey', alpha=0.4) + 
  geom_vline(aes(xintercept=median(Fare, na.rm=T)),
    colour='blue', linetype='dashed', lwd=1) +
  geom_vline(aes(xintercept=mean(Fare, na.rm=T)),
  colour='red', linetype='dashed', lwd=1)
``` 
  
Observamos como al realizar la gráfica la advertencia *"Removed 1 rows containing non-finite values (stat_density)"* nos indica que hay un valor nulo.  

La tarifa de 8.05 coincide con la mediana de los pasajeros de tercera clase que embarcaron en S, por lo que se podría imputar este valor. 

```{r Imputacion Fare}
data$Fare[c(1044)] <- 8.05
data[1044,]
```

Volviendo a representar

```{r Plot nulos Fare 2}
M_fare<- subset(data,data$Pclass == '3' & data$Embarked == 'S')
ggplot(M_fare,  aes(x = Fare)) +
  geom_density(fill = 'grey', alpha=0.4) + 
  geom_vline(aes(xintercept=median(Fare, na.rm=T)),
    colour='blue', linetype='dashed', lwd=1) +
  geom_vline(aes(xintercept=mean(Fare, na.rm=T)),
  colour='red', linetype='dashed', lwd=1)
``` 

Una vez imputado el valor ya no existe advertencia lo que significa que en Fare ya no hay un valor nulo.

- Cabin: *existen 1014 valores perdidos.*     
Para imputar valores **Cabin**  
Esta variable tiene muchos valores perdidos, se podria conseguir predecir la cubierta asignada al pasajero pero es un dato que poco beneficio podría traer ya que se puede realizar el analisis con la combinación entre la tarifa y la clase del pasajero.  


- Embarked: *existen 2 valores perdidos.*      
Para imputar valores **Embarked**  

Mostramos los valores perdidos

```{r}
data[is.na(data$Embarked),]
```

Al ser unicamente dos valores perdidos, se podría sustituir los valores por la media, en base a otros pasajeros de la misma clase y tarifa (Fare). 
Los pasajeros han pagado una tarifa de 80 y pertenecian a primera clase. 

```{r Plot nulos embarked}
embarked_pass_1 <- data %>%
  filter(PassengerId != 62 & PassengerId != 830 & Pclass == 1)
ggplot(embarked_pass_1, aes(x = Embarked, y = Fare, fill = factor(Pclass))) +
  geom_boxplot() +
  geom_hline(aes(yintercept=80), 
    colour='blue', linetype='dashed', lwd=1) 
```


La tarifa de 80 coincide con la media de los pasajeros de primera clase que embarcaron en C, por lo que se podría imputar este puerto. 

```{r Imputacion Embarco}
data$Embarked[c(62, 830)] <- 'C'
```

Otra opción, sería considerar también el sexo, ya que principios del siglo XX, no se caracterizaba por una igualdad de hombres y mujeres.

```{r Plot nulos embarked considerando sexo}
embarked_pass_2 <- data %>%
  filter(PassengerId != 62 & PassengerId != 830 & Pclass == 1 & Sex == "female")
ggplot(embarked_pass_2, aes(x = Embarked, y = Fare, fill = factor(Pclass))) +
  geom_boxplot() +
  geom_hline(aes(yintercept=80), 
    colour='blue', linetype='dashed', lwd=1) 
```

En este caso cualquiera de los 3 puertos tendría una media cercana a 80. Como no creemos que el puerto de embarque este correlacionado con la supervivencia, podríamos dejar cualquiera.

Otra forma de asignar el valor de los puertos de embarque sería asignar el valor más frequente. Calculamos cuantas veces aparece cada puerto de embarque.

```{r Puertos más frecuentes de embarque}
table(data$Embarked)
qplot(Embarked, data = data,  fill= Embarked) + 
  labs (title = "Distribucion Puerto de Embarque", 
        x= "Puerto", y = "Cantidad", fill = "Puerto de embarque")
```

Se muestra como el puerto con mayor frequencia es S, así que finalmente asignaremos este valor.

```{r Imputacion Embarco Definitiva}
data$Embarked[c(62, 830)] <- 'S'
```


A continuación trataremos la variable Name, para crear una variable Title, que nos aporte algo de información. 

A partir de Name obtenemos el título de los nombres

```{r,eval=TRUE,echo=TRUE}
# Mostramos algunos nombres
head(data$Name)
```

Podemos clasificar a las personas por su título.

```{r,eval=TRUE,echo=TRUE}
# Grab passenger title from passenger name
# Referencia:
# https://www.kaggle.com/thilakshasilva/predicting-titanic-survival-using-five-algorithms
data$Title <- gsub("^.*, (.*?)\\..*$", "\\1", data$Name)
```

Mostramos los títulos de las personas que viajaban en el Titanic

```{r,eval=TRUE,echo=TRUE}
#Mostramos la variable Title en función de sex
kable(table(data$Title, data$Sex)) %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

Podemos reasignar las "Mlle" (Madmoiselle) y "Ms" a "Miss", señoritas y la "Mme" (Madame) a "Mrs" (señora). Las ocurrencias con poca frecuencia las podemos agrupar en otros "Other".


```{r,eval=TRUE,echo=TRUE}
# Reagrupando
data$Title[data$Title == 'Mlle' | data$Title == 'Ms'] <- 'Miss' 
data$Title[data$Title == 'Mme']  <- 'Mrs'
Other <- c('Dona', 'Dr', 'Lady', 'the Countess','Capt', 'Col', 'Don', 'Jonkheer', 'Major', 'Rev', 'Sir')
data$Title[data$Title %in% Other]  <- 'Other'
```

Volviendo a representarlos en función del sexo.

```{r,eval=TRUE,echo=TRUE}
# Mostramos el título en función del sexo
kable(table(data$Title, data$Sex)) %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```


La variable Age se podría discretizar y a partir de SibSp y Parch se podría crear una variable con el tamaño de la familia, pero realizaremos un modelo más sencillo, con las variables tratadas hasta ahora.


Una vez añadidos los valores faltantes, se convierten las variables Embarked y Title a factor.

```{r Conversion a factor de embarked}
data$Embarked <- as.factor(data$Embarked)
data$Title <- as.factor(data$Title)
```

Volvemos a añadir la variable Survived y la convertimos a factor.

```{r Survived}
data$Survived <- datos$Survived
data$Survived <- as.factor(data$Survived)
```

Volvemos a mostrar la tabla con el número de valores faltantes. Recordar que en data, no están los valores de la variable Survived. 

```{r Check valores faltantes final}
# Busco primero qué variables tienen valores perdidos
missing_numbers <- sapply(data, function(x) {sum(is.na(x))})
kable(data.frame(Variables = names(missing_numbers), 
                 Datos_faltantes= as.vector(missing_numbers))) %>%
  kable_styling(bootstrap_options = "striped", 
                full_width = F, position = "left")
```

Representamos la tabla con los tipos de los valores.

```{r Tipos variables final}
tipos_new <- sapply(data, class)
kable(data.frame(Variables = names(tipos_new), Tipo_Variable= as.vector(tipos_new))) %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```



**3.2. Identificación y tratamiento de valores extremos. **  

Los valores extremos tendrían sentido en los campos Fare y Age. Procedemos al análisis de los valores extremos representando Fare y Age con los valores extremos y sin ellos.
  
```{r Valores Extremos}
# Referencia:
# https://www.r-bloggers.com/identify-describe-plot-and-remove-the-outliers-from-the-dataset/
outlierKD <- function(dt, var) {
     var_name <- eval(substitute(var),eval(dt))
     na1 <- sum(is.na(var_name))
     m1 <- mean(var_name, na.rm = T)
     par(mfrow=c(2, 2), oma=c(0,0,3,0))
     boxplot(var_name, main="With outliers")
     hist(var_name, main="With outliers", xlab=NA, ylab=NA)
     outlier <- boxplot.stats(var_name)$out
     mo <- mean(outlier)
     var_name <- ifelse(var_name %in% outlier, NA, var_name)
     boxplot(var_name, main="Without outliers")
     hist(var_name, main="Without outliers", xlab=NA, ylab=NA)
     title("Outlier Check", outer=TRUE)
     na2 <- sum(is.na(var_name))
     cat("Outliers identified:", na2 - na1, "n")
     cat("Propotion (%) of outliers:", round((na2 - na1) / sum(!is.na(var_name))*100, 1), "n")
     cat("Mean of the outliers:", round(mo, 2), "n")
     m2 <- mean(var_name, na.rm = T)
     ###
     # cat("Mean without removing outliers:", round(m1, 2), "n")
     # cat("Mean if we remove outliers:", round(m2, 2), "n")
     # response <- readline(prompt="Do you want to remove outliers and to replace with NA? [yes/no]: ")
     # if(response == "y" | response == "yes"){
     #      dt[as.character(substitute(var))] <- invisible(var_name)
     #      assign(as.character(as.list(match.call())$dt), dt, envir = .GlobalEnv)
     #      cat("Outliers successfully removed", "n")
     #      return(invisible(dt))
     # } else{
     #      cat("Nothing changed", "n")
     #      return(invisible(var_name))
     # }
     ###
}
```


```{r Outlier 1}
outlierKD(data, Age)
```

```{r Outlier 2}
outlierKD(data, Fare)
```

Como son perfectamente aceptables las edades y que haya gente que pagara mucho más por su billete, al ser el primer viaje del transatlántico más grande de la epoca, decidimos no cambiar ningún valor.

# 4. Análisis de los datos.

**4.1. Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar)**  

- Análisis estadístico descriptivo.

Se utilizarán las variables de Edad, Clase, Género y Puerto de Embarque para realizar el análisis de los datos. 

La distribución de los pasajeros según indica el siguiente grafico.

```{r}
ggplot(data = data) +
  geom_violin (aes(Pclass, Age, colour = factor(Sex)),draw_quantiles = c(0.25, 0.5, 0.75)) +
  labs (title = "Distribución de Pasajeros", x= "Clase Pasajeros", 
        y = "Edad" , colour = "Género Pasajero") +
  theme_bw()
```
  



Representando la edad de los pasajeros obtenemos:

```{r}
#Test_age <- na.omit(data$Age)
#Test_age <- as.integer(Test_age)
ggplot(data,  aes(x = Age)) +
  geom_histogram(binwidth = 5, fill = 'grey', alpha=0.4) + 
  geom_vline(aes(xintercept=median(Age, na.rm=T)),
    colour='blue', linetype='dashed', lwd=1) +
  geom_vline(aes(xintercept=mean(Age, na.rm=T)),
  colour='red', linetype='dashed', lwd=1) + 
  labs (title = "Distribucion Edades", x= "Edad", y = "Cantidad" )
```

Podemos observar que la media de edad de los pasajeros es de 29.8 años y la mediana es de 28.  


Finalmente realizando unos gráficos de las variables principales, clase, sexo y puerto de embarque.

```{r}
par(mfrow=c(1,2))
ggplot(data,  aes(x = Pclass)) +
  geom_histogram(aes(fill = Pclass) ,stat = "count") + 
  labs (title = "Distribución Clases", x= "Clase", y = "Cantidad", fill = "Clase Pasajero")
qplot(Sex, data = data,  fill= Sex) +
  labs (title = "Distribución Género", x= "Género", y = "Cantidad", fill = "Género Pasajero")
qplot(Embarked, data = data,  fill= Embarked) + 
  labs (title = "Distribución Puerto de Embarque", x= "Puerto", 
        y = "Cantidad", fill = "Puerto de embarque")
```


Observamos que la clase más numerosa es la 3ra clase, el sexo predominante es el masculino y el puerto dónde hubo mayor embarque es el de Southampton, al ser el puerto de origen del trasatlántico.

También resultará interesante, ver que grupos obtuvieron mayor supervivencia:

```{r,eval=TRUE,echo=TRUE}
#Respecto a la Clase
ggplot(filter(data, is.na(Survived)==FALSE), aes(Pclass, fill=Survived)) + 
  geom_bar(aes(y = (..count..)/sum(..count..)), alpha=0.9, position="dodge") +
  scale_fill_brewer(palette = "Reds", direction = -1) +
  scale_y_continuous(labels=percent, breaks=seq(0,0.6,0.05)) +
  ylab("Porcentaje") + 
  ggtitle("Ratio de superviviencia basado en la Clase") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```

Representamos la supervivencia respecto al sexo.

```{r,eval=TRUE,echo=TRUE}
#Respecto al sexo
ggplot(filter(data, is.na(Survived)==FALSE), aes(Sex, fill=Survived)) + 
  geom_bar(aes(y = (..count..)/sum(..count..)), alpha=0.9, position="dodge") +
  scale_fill_brewer(palette = "Purples", direction = -1) +
  scale_y_continuous(labels=percent, breaks=seq(0,0.6,0.05)) +
  ylab("Porcentaje") + 
  ggtitle("Ratio de superviviencia por Sexo") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```

Representamos la supervivencia respecto al título.

```{r,eval=TRUE,echo=TRUE}
#Respecto al título
ggplot(filter(data, is.na(Survived)==FALSE), aes(Title, fill=Survived)) + 
  geom_bar(aes(y = (..count..)/sum(..count..)), alpha=0.9, position="dodge") +
  scale_fill_brewer(palette = "Greens", direction = -1) +
  scale_y_continuous(labels=percent, breaks=seq(0,0.6,0.05)) +
  ylab("Porcentaje") + 
  ggtitle("Ratio de superviviencia por Título") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```


**4.2. Comprobación de la normalidad y homogeneidad de la varianza.**  

Comprobar la normalidad y homogeneidad de la varianza tiene sentido para la variables numéricas Age y Fare.

Comprobamos la normalidad, gráficamente, para Age:

```{r,eval=TRUE,echo=TRUE}
#Hago que los dos ejes tengan el mismo tamaño.
ggqqplot(data$Age, ggtheme = theme(aspect.ratio=1), title = "Age")
```


También se puede aplicar un test Shapiro-Wilk, en el que la hipótesis nula, (H0) es que la muestra proviene de una población normalmente distribuida y la hipótesis alternativa (H1), que la muestra no proviene de una población normalmente distribuida.

```{r,eval=TRUE,echo=TRUE}
# Aplico el test
shapiro.test(data$Age)
```

El valor de W está próximo a 1 y el p-value < 0.05, (el p-value, debería ser p-value>0.05 para seguir una distribución normal) así que se rechaza la hipótesis nula y la muestra no sigue una distribución normal. Como se ve en la gráfica hay menos jóvenes y más con elevada edad que habría en una distribución normal.




A continuación, comprobamos la normalidad de Fare, gráficamente:
```{r,eval=TRUE,echo=TRUE}
#Hago que los dos ejes tengan el mismo tamaño.
ggqqplot(data$Fare, ggtheme = theme(aspect.ratio=1), title = "Fare")
```

Aplicamos el test de Shapiro-Wilk a la variable Fare

```{r,eval=TRUE,echo=TRUE}
# Aplico el test
shapiro.test(data$Fare)
```

En este caso ni siquiera W está cercano a 1, así que se rechaza la hipótesis nula y tampoco sigue una distribución normal.


Comprobamos la homogeneidad de la varianza, dado que hemos visto que los datos no siguen una distribución normal, aplicaremos el test de Fligner-Killeen.

```{r,eval=TRUE,echo=TRUE}
# Aplicamos el test de Fligner-Killeen.
fligner.test(Age ~ Fare, data = data)
```

Dado que la prueba presenta un p-valor inferior al nivel de significancia (<0.05), se rechaza la hipótesis nula de homocedasticidad y se concluye que la variable Age presenta una varianza estadísticamente diferente para la distribución de Fare.



**4.3. Aplicación de pruebas estadísticas para comparar los grupos de datos.**   
*En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc.*  
*Aplicar al menos tres métodos de análisis diferentes.*  

**1 - Contraste de Hipótesis**  
*Comprobar la hipótesis que la 1ra clase tiene mas posibilidades de Sobrevivir.*

H0 : No hay diferencia significativa de sobrevivir entre la clase alta y la clase baja.  
H1 : La clase alta tiene mas probabilidades de sobrevivir.  

```{r}
Pclass_set <- subset(datostrain, Pclass == 1)
#function for z test
z.test = function(a, b, n){
 sample_mean = mean(a)
 pop_mean = mean(b)
 c = nrow(n)
 var_b = var(b)
 zeta = (sample_mean - pop_mean) / (sqrt(var_b/c))
 return(zeta)
}
#call function
z.test(Pclass_set$Survived, datostrain$Survived, Pclass_set)
```

El valor de z de 7.42 afirma la hipótesis alternativa, la clase alta tiene mas probabilidades de sobrevivir.  


**2 - Correlación**  
*Comprobación de correlación entre variables*  

````{r}
chisq.test(data$Sex, data$Pclass)
``` 

Dado que el p valor es menor que 0.05, el género y la clase son significantes y deben de tomarse en cuenta para realizar cualquier modelo. 
  
**3 - Regresión**  
```{r}
fit <- glm(Survived ~ Age + Pclass + Sex + SibSp + Parch + Fare + Embarked, 
           data = datostrain, family = binomial(link = 'logit'))
summary(fit)
```
Se comprueba que existe una fuerte relación entre la variable dependiente Survived y Edad, Clase y Genero (hombre). 

# 5. Representación de los reultados a partir de tablas y gráficas.

Representamos los datos de las variables.  

```{r,eval=TRUE,echo=TRUE}
# Mostramos un histograma para cada variable cuantitativa o un gráfico de barras en caso de que
# sea una variable cualitativa.
for (i in 2:ncol(data)) {
  if (class(data[,i]) != "factor" & class(data[,i]) != "character")  {
    hist(data[,i], freq = TRUE, col = c("steelblue"), 
         main=paste("Distribución de ", 
                    str_to_title(str_replace(colnames(data[i]), "_", " ")), sep = " "),
         xlab= str_to_title(str_replace(colnames(data[i]), "_", " ")))
  }
  else {
    if (class(data[,i]) != "character") {
      barplot(table(data[,i]),
            col = c("orange","yellow","blue","red"),
            main=paste("Distribución de ", 
                    str_to_title(str_replace(colnames(data[i]), "_", " ")), sep = " "),
            xlab= str_to_title(str_replace(colnames(data[i]), "_", " ")))
    }
  }
}
```
  
Creamos un gráfico scatter plot, para ver la correlación de las variables:  

```{r,eval=TRUE,echo=TRUE}
# Referencia:
# https://warwick.ac.uk/fac/sci/moac/people/students/peter_cock/r/iris_plots/
# Función para mostrar la correlación
panel.pearson <- function(x, y, ...) {
horizontal <- (par("usr")[1] + par("usr")[2]) / 2;
vertical <- (par("usr")[3] + par("usr")[4]) / 2;
text(horizontal, vertical, format(abs(cor(x,y)), digits=2))
}
# Gráfico de parejas
pairs(data[c(5,6,7,9)], main = "Data plot en función de las clases", pch = c(22,23,24,25),
      bg = c("yellow","blue","red") [unclass(data[,'Pclass'])],
      upper.panel = panel.pearson)
```


```{r,eval=TRUE,echo=TRUE}
# Referencia:
# https://warwick.ac.uk/fac/sci/moac/people/students/peter_cock/r/iris_plots/
# Función para mostrar la correlación
panel.pearson <- function(x, y, ...) {
horizontal <- (par("usr")[1] + par("usr")[2]) / 2;
vertical <- (par("usr")[3] + par("usr")[4]) / 2;
text(horizontal, vertical, format(abs(cor(x,y)), digits=2))
}
# Gráfico de parejas
pairs(data[c(5,6,7,9)], main = "Data plot en función del sexo", pch = c(22,23,24,25),
      bg = c("blue","red") [unclass(data[,'Sex'])],
      upper.panel = panel.pearson)
```

Antes de pasar a la resolución del problema en sí, de predecir la variable Survived en el conjunto de test, podemos guardar los resultados de los conjuntos de datos tratados.

Para ello, volvemos a separar los datos, tomando sólo las columnas que utilizaremos para la predicción. No se utilizan los datos de Cabin ni de Ticket. Los datos de Name, se han tratado y sustituido por Title.

```{r,eval=TRUE,echo=TRUE}
# Referencia
# https://www.kaggle.com/thilakshasilva/predicting-titanic-survival-using-five-algorithms#exploratory-data-analysis
# Volvemos a partir el conjunto de datos
titanic_train <- data[1:891, c("Survived","Pclass","Sex","Age","SibSp","Parch","Fare","Embarked","Title")]
titanic_test <- data[892:1309, c("Pclass","Sex","Age","SibSp","Parch","Fare","Embarked","Title")]
```

Y guardamos los archivos:

```{r,eval=TRUE,echo=TRUE}
# Guardamos el archivo
write.csv(titanic_train, file = './output/titanic_train_treated.csv', row.names = FALSE, quote=FALSE)
write.csv(titanic_test, file = './output/titanic_test_treated.csv', row.names = FALSE, quote=FALSE)
```


# 6. Resolución del problema. 
**A partir de los resultados obtenidos. ¿cuáles son las conclusiones?. ¿Los resultados permiten responder al problema?** 

Como se trata de predecir una variable binaria, podemos crear un modelo de regresión logística que sea función de las otras variables. 

Utilizaremos una parte del conjunto de train del que conocemos los resultados, para validar los resultados.

```{r,eval=TRUE,echo=TRUE}
# Volvemos a partir el conjunto de datos
set.seed(198)
particion = sample.split(titanic_train$Survived, SplitRatio = 0.8)
train = subset(titanic_train, particion == TRUE)
test = subset(titanic_train, particion == FALSE)
```

```{r,eval=TRUE,echo=TRUE}
# Referencia:
# https://rpubs.com/emilopezcano/logit
# Modelo de regresión logística
titanic.logit <- glm(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title,
                    data = titanic_train, family = "binomial"(link="logit"))
summary(titanic.logit)
```

Vemos como hay variables que no tienen tanta importancia en el clasificador como Sex y Embarked.
Aplicamos la función step para ir quitando estas variables que no tienen tanta importancia.

```{r,eval=TRUE,echo=TRUE}
# Modelo de regresión logística
titanic.logit <- step(titanic.logit)
```
```{r,eval=TRUE,echo=TRUE}
# Modelo de regresión logística
summary(titanic.logit)
```
```{r,eval=TRUE,echo=TRUE}
# Modelo de regresión logística
titanic.logit <- step(titanic.logit)
```
```{r,eval=TRUE,echo=TRUE}
# Modelo de regresión logística
vif(titanic.logit)
```
```{r,eval=TRUE,echo=TRUE}
# Modelo de regresión logística
durbinWatsonTest(titanic.logit)
```
```{r,eval=TRUE,echo=TRUE}
# Comprobamos los resultados en el conjunto de test de validación
prob_pred = predict(titanic.logit, type = 'response', newdata = test)
y_pred = ifelse(prob_pred > 0.5, 1, 0)
head(y_pred)
```

Comprobamos la matriz de confusion
```{r,eval=TRUE,echo=TRUE}
# Comprobamos la matriz de confusión
table(test$Survived, y_pred > 0.5)
#kable(table(test$Survived, (y_pred > 0.5)) %>%
#  kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```
Calculamos la precisión del modelo.
```{r,eval=TRUE,echo=TRUE}
error <- mean(test$Survived != y_pred) # Misclassification error
paste('Accuracy',round(1-error,4))
```
Finalmente, calculamos los valores finales
```{r,eval=TRUE,echo=TRUE}
# Calculamos las predicciones
titanic_prob = predict(titanic.logit, newdata = titanic_test)
titanic_pred = ifelse(titanic_prob > 0.5, 1, 0)
```
```{r,eval=TRUE,echo=TRUE}
# Guardamos los resultados
results <- data.frame(PassengerID = data[892:1309,"PassengerId"], Survived = titanic_pred)
```
```{r,eval=TRUE,echo=TRUE}
# Guardamos el archivo
write.csv(results, file = './output/PrediccionSupervivenciaTitanic.csv', row.names = FALSE, quote=FALSE)
```

Los resultados han permitido responder al problema, dando una puntuación de 0.80382, que está bastante bien, es bastante superior, a lo que sería un predictor aleatorio. A partir de aquí se podría mejorar el modelo de predicción considerando otros métodos y creando por ejemplo un "stacking"" de ellos. 



# 7. Código. Hay que adjuntar el código, preferiblemente en R, con el que se ha realizado la limpieza, análisis y represntación de los datos.

El código está integrado en el documento .Rmd y sale convenientemente formateado cuando se exporta por Knit en .html o .pdf.

Participación de los integrantes del equipo:

```{r,eval=TRUE,echo=TRUE}
# Creamos una tabla en formato kagle para mostrar la participación:
participantes <-  c("Investigación previa", "L.G, J.L.M.", 
                    "Redacción de las respuestas", "L.G, J.L.M.", 
                    "Desarrollo código", "L.G, J.L.M.")
df <- matrix(participantes, ncol = 2, byrow = TRUE) 
colnames(df) <- c("Contribuciones", "Firmas") 
kable(df) %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

# 8. Bibliografía.
